{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMYcMZxdfLF8+O8KmlspZd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thestbobo/DLML_FL_project/blob/main/colab_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Environment Setup**"
      ],
      "metadata": {
        "id": "L51bSihQEz-a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f1EUz3AzEYn9",
        "outputId": "85bf7525-1065-48e8-86b2-240b1393d810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DLML_FL_project'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 117 (delta 12), reused 10 (delta 10), pack-reused 101 (from 1)\u001b[K\n",
            "Receiving objects: 100% (117/117), 25.18 KiB | 12.59 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n",
            "/content/DLML_FL_project\n"
          ]
        }
      ],
      "source": [
        "# Clone GitHub repository\n",
        "!git clone https://github.com/thestbobo/DLML_FL_project.git\n",
        "%cd DLML_FL_project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "mxgzGVP8wLdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DLML_FL_project\n"
      ],
      "metadata": {
        "id": "8im8JrS74eXo",
        "outputId": "217bfcf6-f996-4a99-ee54-f29287634b68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'DLML_FL_project'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pull after local commits**"
      ],
      "metadata": {
        "id": "p0A5t1Ds9ze0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main\n"
      ],
      "metadata": {
        "id": "s67IDKW84fkZ",
        "outputId": "feb604b9-9d12-4dd0-cad9-8ed0b2e29a51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/thestbobo/DLML_FL_project\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Environment check**"
      ],
      "metadata": {
        "id": "Fq6CSsDxFl_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA avaiable:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "WLGGMmyHFqbr",
        "outputId": "d19793e1-0831-4ab1-ecb9-e68b0ab0295c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA avaiable: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Configuration (hyperparameters) and Paths (in/out)**\n",
        "\n",
        "-Example file for config.yaml\n",
        "\n",
        "batch_size: 64\n",
        "\n",
        "lr: 0.01\n",
        "\n",
        "-Example of code usage:\n",
        "\n",
        "print(config[\"batch_size\"]) --> 64\n"
      ],
      "metadata": {
        "id": "rufqzKaaF7xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# load YAML config\n",
        "with open(\"config/config.yaml\") as f:\n",
        "  config = yaml.safe_load(f)\n",
        "\n",
        "# Setup paths and device\n",
        "DATA_DIR = Path(\"./data\")\n",
        "DEVICE= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config['batch_size'] = 256\n",
        "\n",
        "print(config)"
      ],
      "metadata": {
        "id": "KlJG1U1WGeiN",
        "outputId": "ec1989bc-7bed-4a26-9f95-ea35b0dcb052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_size': 256, 'val_split': 0.1, 'num_workers': 2, 'learning_rate': 0.05, 'weight_decay': 0.0005, 'momentum': 0.9, 't_max': 50, 'epochs': 50, 'data_dir': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gzAeGoLJvlqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and rsults visualisazion**"
      ],
      "metadata": {
        "id": "XsshK5U0vqkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_API_KEY=9efaa9e72ef3b211a9239aed9b1ea7dcb2f680ad"
      ],
      "metadata": {
        "id": "F8Wh8RJTvlRf",
        "outputId": "46d321f1-664e-40c0-949c-6d5235ba7c56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_API_KEY=9efaa9e72ef3b211a9239aed9b1ea7dcb2f680ad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "id": "8dzzNjMtv53Y",
        "outputId": "8982605f-6147-4110-a4b3-82c47cd8f30b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU avaiable: Tesla T4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms297466\u001b[0m (\u001b[33ms297466-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/DLML_FL_project/wandb/run-20250416_132011-u4w6fe7j\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-jazz-62\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/s297466-politecnico-di-torino/CIFAR-100_centralized\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/s297466-politecnico-di-torino/CIFAR-100_centralized/runs/u4w6fe7j\u001b[0m\n",
            "100% 169M/169M [00:13<00:00, 12.6MB/s]\n",
            "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_deitsmall16_pretrain.pth\n",
            "100% 82.7M/82.7M [00:00<00:00, 231MB/s]\n",
            "Epoch 1/50 | Train Loss: 3.3320 | Train Acc: 0.2554 | Val Acc: 0.3800\n",
            "Checkpoint saved with Acc=0.26%\n",
            "Best model saved with Acc=0.38%\n",
            "Epoch 2/50 | Train Loss: 6.7480 | Train Acc: 0.3271 | Val Acc: 0.3490\n",
            "Epoch 3/50 | Train Loss: 12.9707 | Train Acc: 0.3481 | Val Acc: 0.3548\n",
            "Epoch 4/50 | Train Loss: 19.8795 | Train Acc: 0.3570 | Val Acc: 0.3780\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "Epoch 5/50 | Train Loss: 26.7225 | Train Acc: 0.3665 | Val Acc: 0.3470\n",
            "Epoch 6/50 | Train Loss: 32.5143 | Train Acc: 0.3738 | Val Acc: 0.3486\n",
            "Checkpoint saved with Acc=0.37%\n",
            "Epoch 7/50 | Train Loss: 32.8813 | Train Acc: 0.3926 | Val Acc: 0.3574\n",
            "Epoch 8/50 | Train Loss: 33.0746 | Train Acc: 0.3957 | Val Acc: 0.3720\n",
            "Epoch 9/50 | Train Loss: 32.5682 | Train Acc: 0.4036 | Val Acc: 0.3764\n",
            "Epoch 10/50 | Train Loss: 31.8734 | Train Acc: 0.4067 | Val Acc: 0.3718\n",
            "Train Epoch 11:  29% 202/704 [02:46<06:13,  1.34it/s]"
          ]
        }
      ]
    }
  ]
}